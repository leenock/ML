print(rf)
print(rf_random)
attributes(rf)
attributes(rf_random)
rf_random$metric
# Tune using Grid Search ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(123)
tunegrid <- expand.grid(.mtry=c(1:8))
rf_gridsearch <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
print(rf_gridsearch)
print(rf_random)
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
print(rf_grid)
plot(rf_grid)
attributes(rf_grid)
rf_grid$finalModel
rf_random$finalModel
print(rf_random)
print(rf_grid)
# Tuning on mtry and ntree
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(.mtry=c(sqrt(ncol(training_set))))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
dotplot(results)
# Tuning on mtry and ntree
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(mtry=c(sqrt(ncol(training_set))))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
rf_grid$finalModel
summary(results)
attributes(results)
results$models
results$values
# Tuning on mtry and ntree
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(.mtry=c(1:8))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
dotplot(results)
attributes(results)
results$values
attributes(results)
results$models
# Tuning on mtry and ntree
control = trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid = expand.grid(.mtry=c(1:8))
modellist = list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit = train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key_1 <- toString(ntree)
key_2 = toString(mtry)
modellist[[key_1, key_2]] = fit
}
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key, tunegrid]] <- fit
}
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] [[tunegrid]] <- fit
}
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree, mtry)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
# Tune using Grid Search ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(123)
tunegrid <- expand.grid(.mtry=c(sqrt(ncol(training_set))))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
# Tuning on mtry and ntree
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(.mtry=c(sqrt(ncol(training_set))))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# Tuning on mtry and ntree
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(.mtry=c(sqrt(ncol(training_set))))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
# Tuning on mtry and ntree
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(.mtry=sqrt(ncol(training_set)))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
dotplot(results)
attributes(results)
print(results)
attributes(rf_grid)
rf_grid$results
rf_grid$finalModel
# Tuning on mtry and ntree ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(.mtry=sqrt(ncol(training_set)))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500) & mtry=sqrt(ncol(training_set))) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
for (ntree in c(500, 1000, 1500, 2000, 2500) & (mtry in c(1:8))) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# Tuning on mtry and ntree ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(mtry=c(1:8))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
# Tuning on mtry and ntree ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
# tunegrid <- expand.grid(mtry=c(1:8))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
results$values
results$metrics
results$models
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", trControl=control, ntree=ntree, mtry = expand.grid(mtry=c(1:8)))
key <- toString(ntree)
modellist[[key]] <- fit
}
warnings()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", trControl=control, ntree=ntree, mtry = 2)
key <- toString(ntree)
modellist[[key]] <- fit
}
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", trControl=control, tunegrid = tunegrid, ntree=ntree)
key <- toString(ntree)
# compare results
results <- resamples(modellist)
summary(results)
# Tuning on mtry and ntree ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(mtry=c(1:8))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", trControl=control, tuneGrid = tunegrid, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
tunegrid <- mtry=2
tuneRF(training_set[ ,-9], training_set$V11,
stepFactor=0.5,
plot = TRUE,
ntreeTry = 400,
trace = TRUE,
improve = 0.05)
rf1 <- randomForest(V11~.,data = training_set,
ntreeTry = 400,
mtry=2,
importance = TRUE,
proximity = TRUE)
print(rf1)
training_set
varImpPlot(rf)
importance(rf)
varUsed(rf)
??varUsed
# Number of nodes for trees
hist(treesize(rf),
main = "No. of nodes for trees",
col = "green")
# Model building
library(randomForest)
set.seed(345)
rf <- randomForest(V11~.,data = training_set )
print(rf)
attributes(rf)
# Number of nodes for trees
hist(treesize(rf),
main = "No. of nodes for trees",
col = "green")
varImpPlot(rf)
help(randomForest)
df <- read.table("breast-cancer-wisconsin.data", na.strings = "?", sep=",")
str(df)
df <- df [ ,-1]
df$V11 <- factor(df$V11, levels=c(2,4), labels=c("1", "2"))
# Removing columns with missing Values
sum (is.na(df))
colSums(sapply(df,is.na))
df$V7 <- NULL
str(df)
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(df$V11, SplitRatio = 0.7)
training_set = subset(df, split == TRUE)
test_set = subset(df, split == FALSE)
str(training_set)
# Model building
library(randomForest)
set.seed(123)
rf <- randomForest(V11~., data = training_set)
print(rf)
attributes(rf)
rf$err.rate
attributes(rf)
rf$mtry
rf$importance
attributes(rf)
rf$confusion
rf <- randomForest(V11~., data = training_set, ntree=1000)
print(rf)
rf <- randomForest(V11~., data = training_set, ntree=1500)
print(rf)
rf <- randomForest(V11~., data = training_set, ntree=2000)
print(rf)
rf <- randomForest(V11~., data = training_set, ntree=1000, mtry = 4)
print(rf)
p1 <- predict(rf, training_set)
p1
cm_train <- table (p1, training_set$V11)
cm_train
train_accuracy = sum(diag(cm_train)/sum(cm_train))
train_accuracy
p2 <- predict(rf, test_set)
cm_test <- table(p2, test_set$V11)
cm_test
test_accuracy = sum(diag(cm_test)/sum(cm_test))
test_accuracy
plot(rf)
rf <- randomForest(V11~., data = training_set)
print(rf)
# Model building
library(randomForest)
set.seed(123)
rf <- randomForest(V11~., data = training_set)
print(rf)
attributes(rf)
p1 <- predict(rf, training_set)
p1
cm_train <- table (p1, training_set$V11)
cm_train
train_accuracy = sum(diag(cm_train)/sum(cm_train))
train_accuracy
p2 <- predict(rf, test_set)
cm_test <- table(p2, test_set$V11)
cm_test
test_accuracy = sum(diag(cm_test)/sum(cm_test))
test_accuracy # Accuracy
plot(rf)
library(caret)
confusionMatrix(p1, training_set$V11) # Root mean squared error
confusionMatrix(p2, test_set$V11) # Mean Absolute Error
# Tuning mtry --> mtry: Number of variables randomly sampled as candidates at each split.
library(caret)
str(training_set)
tuneRF(training_set[ ,-9], training_set$V11,
stepFactor=0.5,
plot = TRUE,
ntreeTry = 500,
trace = TRUE,
improve = 0.05)
tuneRF(training_set[ ,-9], training_set$V11,
stepFactor=0.5,
plot = TRUE,
ntreeTry = 1000,
trace = TRUE,
improve = 0.05)
tuneRF(training_set[ ,-9], training_set$V11,
stepFactor=0.5,
plot = TRUE,
ntreeTry = 1500,
trace = TRUE,
improve = 0.05)
tuneRF(training_set[ ,-9], training_set$V11,
stepFactor=0.5,
plot = TRUE,
ntreeTry = 500,
trace = TRUE,
improve = 0.05)
# Tuning mtry --> mtry: Number of variables randomly sampled as candidates at each split.
library(caret)
str(training_set)
tuneRF(training_set[ ,-9], training_set$V11,
stepFactor=0.5,
plot = TRUE,
ntreeTry = 500,
trace = TRUE,
improve = 0.05)
print(rf)
rf1 <- randomForest(V11~.,data = training_set,
ntreeTry = 500,
mtry=2,
importance = TRUE,
proximity = TRUE)
print(rf1)
p1 <- predict(rf1, training_set)
cm1 <- table(p1, training_set$V11)
cm1
p2 <- predict(rf1, test_set)
cm2 <- table(p2, test_set$V11)
# Number of nodes for trees
hist(treesize(rf),
main = "No. of nodes for trees",
col = "green")
varImpPlot(rf)
rf$importance
varUsed(rf)
importance(rf)
# Tune using Random Search ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
control = trainControl(method="repeatedcv", number=10, repeats=3, search="random")
set.seed(123)
# mtry = sqrt(ncol(training_set))
rf_random = train(V11~., data=training_set, method="rf", metric="Accuracy", tuneLength=15, trControl=control)
print(rf_random)
plot(rf_random)
attributes(rf_random)
rf_random$finalModel
rf$confusion
print(rf)
mtry = sqrt(ncol(training_set))
rf_random = train(V11~., data=training_set, method="rf", metric="Accuracy", tuneLength=15, trControl=control, mtry = mtry)
sqrt(8)
sqrt(40)
# Tune using Grid Search ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(123)
tunegrid <- expand.grid(.mtry=c(1:8)) # mtry = sqrt(ncol(training_set))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
print(rf_grid)
plot(rf_grid)
rf_grid$finalModel
print(rf_random)
print(rf_grid)
# Tuning on mtry and ntree ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(mtry=c(1:8))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", trControl=control, tuneGrid = tunegrid, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# Tuning on mtry and ntree ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid(mtry=c(1:8))
modellist <- list()
for (ntree in c(500, 1000, 1500, 2000, 2500)) {
set.seed(123)
fit <- train(V11~., data=training_set, method="rf", metric="Accuracy", trControl=control, tuneGrid = tunegrid, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results
results <- resamples(modellist)
summary(results)
dotplot(results)
attributes(results)
# Tune using Random Search ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
control = trainControl(method="repeatedcv", number=10, repeats=3, search="random")
set.seed(123)
tunegrid <- expand.grid(.mtry=c(1:8))
rf_random = train(V11~., data=training_set, method="rf", metric="Accuracy", tuneLength=15, tuneGrid=tunegrid, trControl=control)
print(rf_random)
plot(rf_random)
tunegrid <- expand.grid(.mtry=c(1:8)) # mtry = sqrt(ncol(training_set))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
print(rf_grid)
rf_grid$finalModel
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
tunegrid <- expand.grid{
mtry=c(1:8),
ntree = c(500, 1000, 1500, 2000, 2500)
}
tunegrid <- expand.grid{
mtry=c(1:8)
ntree = c(500, 1000, 1500, 2000, 2500)
}
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(123)
tunegrid <- expand.grid(.mtry = c(1:8), .ntree = c(500, 1000, 1500, 2000, 2500))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry = sqrt(ncol(training_set)), .ntree = c(500, 1000, 1500, 2000, 2500))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry = ncol(training_set), .ntree = c(500, 1000, 1500, 2000, 2500))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry = c(2, 4, 6, 8), .ntree = c(500, 1000, 1500, 2000, 2500))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.mtry = c(2, 4, 6, 8))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
print(rf_grid)
tunegrid <- expand.grid(mtry = c(1:8))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(mtry = c(1:8), ntree = c(500, 1000, 1500, 2000, 2500))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(mtry = c(2, 4, 6, 8), ntree = c(500, 1000, 1500, 2000, 2500))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(123)
tunegrid <- expand.grid(ntree = c(500, 1000, 1500, 2000, 2500))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(ntree = c(500:2500))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(.ntree = c(500:2500))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(ntree = c(500:2500), mtry = c(1:8))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(ntree = seq(500, 2500, by = 500), mtry = c(1:8))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(ntree = seq(500, 2500, by = 500), mtry = c(2, 4, 6, 8))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(ntree = seq(500, 2500, by = 500))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
tunegrid <- expand.grid(ntree = c(500, 1000, 1500, 2000, 2500))
rf_grid <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(.mtry=c(1:15), .ntree=c(500, 1000, 1500, 2000, 2500))
set.seed(123)
custom <- train(V11~., data=training_set, method=customRF, metric="Accuracy", tuneGrid=tunegrid, trControl=control)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(.mtry=c(1:15), .ntree=c(500, 1000, 1500, 2000, 2500))
set.seed(123)
custom <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
control <- trainControl(method="repeatedcv", number=10, repeats=3, search = "grid")
tunegrid <- expand.grid(.mtry=c(1:15), .ntree=c(500, 1000, 1500, 2000, 2500))
set.seed(123)
custom <- train(V11~., data=training_set, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
